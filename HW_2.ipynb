{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppzahhfxDv2d",
        "outputId": "8ef0d9b1-6c25-44bb-869d-65a4b2c08be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# It imports the Pandas library as \"pd\" alias and reads a CSV file located at '/content/drive/My Drive/stock_prices.csv' into a DataFrame named \"stock_prices_df\".\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the file path in my Google Drive\n",
        "file_path = '/content/drive/My Drive/stock_prices.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "stock_prices_df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "h4-bggWWEM52"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the \"Close\" column of the DataFrame\n",
        "close_values = stock_prices_df['Close']\n",
        "\n",
        "# Print the first few values of the \"Close\" column\n",
        "print(close_values.head())\n",
        "\n",
        "\n",
        "print(close_values.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68zWtBU4ECWd",
        "outputId": "42f67741-9f50-4bb8-eed8-8d9bf82895f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    2742.0\n",
            "1     571.0\n",
            "2    3210.0\n",
            "3    1550.0\n",
            "4    3330.0\n",
            "Name: Close, dtype: float64\n",
            "count    2.324923e+06\n",
            "mean     2.594023e+03\n",
            "std      3.576538e+03\n",
            "min      1.400000e+01\n",
            "25%      1.022000e+03\n",
            "50%      1.811000e+03\n",
            "75%      3.030000e+03\n",
            "max      1.095500e+05\n",
            "Name: Close, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new class intervals based on quartiles or percentiles of Close prices\n",
        "q1 = stock_prices_df['Close'].quantile(0.25)\n",
        "q2 = stock_prices_df['Close'].quantile(0.50)\n",
        "q3 = stock_prices_df['Close'].quantile(0.75)\n",
        "class_intervals = [(0, q1), (q1, q2), (q2, q3), (q3, stock_prices_df['Close'].max() + 1)]  # Add 1 to include the maximum value\n",
        "\n",
        "# Define function to assign classes based on target value\n",
        "def assign_class(value):\n",
        "    for i, interval in enumerate(class_intervals, start=1):\n",
        "        if interval[0] <= value < interval[1]:  # Adjust the condition to include values in the third quartile\n",
        "            return f'Class {i}'\n",
        "    return 'Outside Range'\n",
        "\n",
        "# Apply function to assign classes to each data point\n",
        "stock_prices_df['Class'] = stock_prices_df['Close'].apply(assign_class)\n",
        "\n",
        "# Display the DataFrame with assigned classes\n",
        "print(stock_prices_df[['RowId', 'Close', 'Class']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQuCQx4qD604",
        "outputId": "83d9985c-27f5-478f-91ae-775e6b500a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 RowId   Close    Class\n",
            "0        20170104_1301  2742.0  Class 3\n",
            "1        20170104_1332   571.0  Class 1\n",
            "2        20170104_1333  3210.0  Class 4\n",
            "3        20170104_1376  1550.0  Class 2\n",
            "4        20170104_1377  3330.0  Class 4\n",
            "...                ...     ...      ...\n",
            "2332526  20211203_9990   528.0  Class 1\n",
            "2332527  20211203_9991   794.0  Class 1\n",
            "2332528  20211203_9993  1645.0  Class 2\n",
            "2332529  20211203_9994  2389.0  Class 3\n",
            "2332530  20211203_9997   696.0  Class 1\n",
            "\n",
            "[2332531 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the dataset\n",
        "dataset_size = stock_prices_df.shape\n",
        "print(\"Dataset Size:\", dataset_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P__vcsMD2Wo",
        "outputId": "7906f027-0876-42dd-d343-af2206864614"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size: (2332531, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# To make my life easier so I don't have to type out a longer variable name\n",
        "df = stock_prices_df\n"
      ],
      "metadata": {
        "id": "nhV1eAFtNfGG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n"
      ],
      "metadata": {
        "id": "srrAMrLnNpGj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check for duplicate records\n",
        "duplicates = df.duplicated().sum()\n",
        "print(\"Number of Duplicate Records:\", duplicates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlBv1kmJNtQq",
        "outputId": "125395ca-3df0-4c6b-953c-248ea121ef04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Duplicate Records: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for format inconsistencies in RowId\n",
        "row_id_format_inconsistencies = df[~df['RowId'].str.match(r'\\d{8}_\\d{4}$')]\n",
        "print(\"Format Inconsistencies in RowId:\")\n",
        "print(row_id_format_inconsistencies)\n",
        "\n",
        "# Check for format inconsistencies in SecuritiesCode\n",
        "securities_code_format_inconsistencies = df[~df['SecuritiesCode'].astype(str).str.isdigit()]\n",
        "print(\"\\nFormat Inconsistencies in SecuritiesCode:\")\n",
        "print(securities_code_format_inconsistencies)\n",
        "\n",
        "# Check for unexpected values in Open, High, Low, Close\n",
        "price_columns = ['Open', 'High', 'Low', 'Close']\n",
        "price_format_inconsistencies = df[~df[price_columns].applymap(lambda x: isinstance(x, (int, float)))].dropna()\n",
        "print(\"\\nFormat Inconsistencies in Price Columns:\")\n",
        "print(price_format_inconsistencies)\n",
        "\n",
        "# Check for format inconsistencies in Volume\n",
        "volume_format_inconsistencies = df[~df['Volume'].astype(str).str.isdigit()]\n",
        "print(\"\\nFormat Inconsistencies in Volume:\")\n",
        "print(volume_format_inconsistencies)\n",
        "\n",
        "# Check for unexpected values in AdjustmentFactor\n",
        "adjustment_factor_format_inconsistencies = df[~df['AdjustmentFactor'].apply(lambda x: isinstance(x, (int, float)))]\n",
        "print(\"\\nFormat Inconsistencies in AdjustmentFactor:\")\n",
        "print(adjustment_factor_format_inconsistencies)\n",
        "\n",
        "\n",
        "\n",
        "# Check for unexpected values in Target\n",
        "Target_inconsistencies = df[~df['Target'].isnull()]\n",
        "print(\"\\nFormat Inconsistencies in Target:\")\n",
        "print(Target_inconsistencies)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ik27onHNwCd",
        "outputId": "ddf7ef14-d982-439c-b7b3-933db82aab9b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Format Inconsistencies in RowId:\n",
            "Empty DataFrame\n",
            "Columns: [RowId, Date, SecuritiesCode, Open, High, Low, Close, Volume, AdjustmentFactor, ExpectedDividend, SupervisionFlag, Target, Class]\n",
            "Index: []\n",
            "\n",
            "Format Inconsistencies in SecuritiesCode:\n",
            "Empty DataFrame\n",
            "Columns: [RowId, Date, SecuritiesCode, Open, High, Low, Close, Volume, AdjustmentFactor, ExpectedDividend, SupervisionFlag, Target, Class]\n",
            "Index: []\n",
            "\n",
            "Format Inconsistencies in Price Columns:\n",
            "Empty DataFrame\n",
            "Columns: [RowId, Date, SecuritiesCode, Open, High, Low, Close, Volume, AdjustmentFactor, ExpectedDividend, SupervisionFlag, Target, Class]\n",
            "Index: []\n",
            "\n",
            "Format Inconsistencies in Volume:\n",
            "Empty DataFrame\n",
            "Columns: [RowId, Date, SecuritiesCode, Open, High, Low, Close, Volume, AdjustmentFactor, ExpectedDividend, SupervisionFlag, Target, Class]\n",
            "Index: []\n",
            "\n",
            "Format Inconsistencies in AdjustmentFactor:\n",
            "Empty DataFrame\n",
            "Columns: [RowId, Date, SecuritiesCode, Open, High, Low, Close, Volume, AdjustmentFactor, ExpectedDividend, SupervisionFlag, Target, Class]\n",
            "Index: []\n",
            "\n",
            "Format Inconsistencies in Target:\n",
            "                 RowId       Date  SecuritiesCode    Open    High     Low  \\\n",
            "0        20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0   \n",
            "1        20170104_1332 2017-01-04            1332   568.0   576.0   563.0   \n",
            "2        20170104_1333 2017-01-04            1333  3150.0  3210.0  3140.0   \n",
            "3        20170104_1376 2017-01-04            1376  1510.0  1550.0  1510.0   \n",
            "4        20170104_1377 2017-01-04            1377  3270.0  3350.0  3270.0   \n",
            "...                ...        ...             ...     ...     ...     ...   \n",
            "2332526  20211203_9990 2021-12-03            9990   514.0   528.0   513.0   \n",
            "2332527  20211203_9991 2021-12-03            9991   782.0   794.0   782.0   \n",
            "2332528  20211203_9993 2021-12-03            9993  1690.0  1690.0  1645.0   \n",
            "2332529  20211203_9994 2021-12-03            9994  2388.0  2396.0  2380.0   \n",
            "2332530  20211203_9997 2021-12-03            9997   690.0   711.0   686.0   \n",
            "\n",
            "          Close   Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
            "0        2742.0    31400               1.0               NaN            False   \n",
            "1         571.0  2798500               1.0               NaN            False   \n",
            "2        3210.0   270800               1.0               NaN            False   \n",
            "3        1550.0    11300               1.0               NaN            False   \n",
            "4        3330.0   150800               1.0               NaN            False   \n",
            "...         ...      ...               ...               ...              ...   \n",
            "2332526   528.0    44200               1.0               NaN            False   \n",
            "2332527   794.0    35900               1.0               NaN            False   \n",
            "2332528  1645.0     7200               1.0               NaN            False   \n",
            "2332529  2389.0     6500               1.0               NaN            False   \n",
            "2332530   696.0   381100               1.0               NaN            False   \n",
            "\n",
            "           Target    Class  \n",
            "0        0.000730  Class 3  \n",
            "1        0.012324  Class 1  \n",
            "2        0.006154  Class 4  \n",
            "3        0.011053  Class 2  \n",
            "4        0.003026  Class 4  \n",
            "...           ...      ...  \n",
            "2332526  0.034816  Class 1  \n",
            "2332527  0.025478  Class 1  \n",
            "2332528 -0.004302  Class 2  \n",
            "2332529  0.009098  Class 3  \n",
            "2332530  0.018414  Class 1  \n",
            "\n",
            "[2332293 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Missing Data\n",
        "missing_data = df.isnull().sum()\n",
        "print(\"Missing Data:\\n\", missing_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_MeEVzFOUc3",
        "outputId": "62f69ed3-a1dd-483e-afc1-d2b993936e2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Data:\n",
            " RowId                     0\n",
            "Date                      0\n",
            "SecuritiesCode            0\n",
            "Open                   7608\n",
            "High                   7608\n",
            "Low                    7608\n",
            "Close                  7608\n",
            "Volume                    0\n",
            "AdjustmentFactor          0\n",
            "ExpectedDividend    2313666\n",
            "SupervisionFlag           0\n",
            "Target                  238\n",
            "Class                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['ExpectedDividend'], inplace=True)"
      ],
      "metadata": {
        "id": "7oF4J26DObJW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate median for each column\n",
        "median_open = df['Open'].median()\n",
        "median_high = df['High'].median()\n",
        "median_low = df['Low'].median()\n",
        "median_close = df['Close'].median()\n",
        "median_Target = df['Target'].median()\n",
        "\n",
        "\n",
        "# Fill missing values with median\n",
        "df['Open'].fillna(median_open, inplace=True)\n",
        "df['High'].fillna(median_high, inplace=True)\n",
        "df['Low'].fillna(median_low, inplace=True)\n",
        "df['Close'].fillna(median_close, inplace=True)\n",
        "df['Target'].fillna(median_Target, inplace=True)\n"
      ],
      "metadata": {
        "id": "5rQo9N7LPub-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recheck missingness\n",
        "print(\"Missing Data After Imputation:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRd0nbfmQDDg",
        "outputId": "b5efc4bc-2a7e-4db7-ba04-30e657ea4040"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Data After Imputation:\n",
            " RowId               0\n",
            "Date                0\n",
            "SecuritiesCode      0\n",
            "Open                0\n",
            "High                0\n",
            "Low                 0\n",
            "Close               0\n",
            "Volume              0\n",
            "AdjustmentFactor    0\n",
            "SupervisionFlag     0\n",
            "Target              0\n",
            "Class               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to detect outliers based on the IQR method\n",
        "def detect_outliers(column):\n",
        "    Q1 = column.quantile(0.25)\n",
        "    Q3 = column.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return (column < lower_bound) | (column > upper_bound)\n",
        "\n",
        "# Apply outlier detection\n",
        "outliers_open = detect_outliers(df['Open']).sum()\n",
        "outliers_high = detect_outliers(df['High']).sum()\n",
        "outliers_low = detect_outliers(df['Low']).sum()\n",
        "outliers_close = detect_outliers(df['Close']).sum()\n",
        "outliers_volume = detect_outliers(df['Volume']).sum()\n",
        "outliers_adjustment_factor = detect_outliers(df['AdjustmentFactor']).sum()\n",
        "\n",
        "\n",
        "outliers_summary = {\n",
        "    'Open Outliers': outliers_open,\n",
        "    'High Outliers': outliers_high,\n",
        "    'Low Outliers': outliers_low,\n",
        "    'Close Outliers': outliers_close,\n",
        "    'Volume Outliers': outliers_volume,\n",
        "    'AdjustmentFactor Outliers': outliers_adjustment_factor\n",
        "\n",
        "}\n",
        "\n",
        "outliers_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtXu_cpsQGvO",
        "outputId": "b2ff5cae-3712-4ebf-c1a5-b8ff43dccf2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Open Outliers': 145183,\n",
              " 'High Outliers': 145803,\n",
              " 'Low Outliers': 144944,\n",
              " 'Close Outliers': 145371,\n",
              " 'Volume Outliers': 308239,\n",
              " 'AdjustmentFactor Outliers': 730}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Summary statistics for the 'Volume' column\n",
        "volume_stats = df['Volume'].describe()\n",
        "\n",
        "# Summary statistics for the 'AdjustmentFactor' column\n",
        "adjustment_factor_stats = df['AdjustmentFactor'].describe()\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"Summary Statistics for Volume Column:\")\n",
        "print(volume_stats)\n",
        "print(\"\\nSummary Statistics for AdjustmentFactor Column:\")\n",
        "print(adjustment_factor_stats)\n",
        "\n",
        "# Skewness and kurtosis for both columns\n",
        "volume_skewness = df['Volume'].skew()\n",
        "volume_kurtosis = df['Volume'].kurtosis()\n",
        "\n",
        "adjustment_factor_skewness = df['AdjustmentFactor'].skew()\n",
        "adjustment_factor_kurtosis = df['AdjustmentFactor'].kurtosis()\n",
        "\n",
        "print(\"\\nSkewness for Volume Column:\", volume_skewness)\n",
        "print(\"Kurtosis for Volume Column:\", volume_kurtosis)\n",
        "\n",
        "print(\"\\nSkewness for AdjustmentFactor Column:\", adjustment_factor_skewness)\n",
        "print(\"Kurtosis for AdjustmentFactor Column:\", adjustment_factor_kurtosis)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80qLoT3OQMxV",
        "outputId": "4f9fde2b-77f6-4ab7-d673-319218d07e18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics for Volume Column:\n",
            "count    2.332531e+06\n",
            "mean     6.919366e+05\n",
            "std      3.911256e+06\n",
            "min      0.000000e+00\n",
            "25%      3.030000e+04\n",
            "50%      1.071000e+05\n",
            "75%      4.021000e+05\n",
            "max      6.436540e+08\n",
            "Name: Volume, dtype: float64\n",
            "\n",
            "Summary Statistics for AdjustmentFactor Column:\n",
            "count    2.332531e+06\n",
            "mean     1.000508e+00\n",
            "std      6.773040e-02\n",
            "min      1.000000e-01\n",
            "25%      1.000000e+00\n",
            "50%      1.000000e+00\n",
            "75%      1.000000e+00\n",
            "max      2.000000e+01\n",
            "Name: AdjustmentFactor, dtype: float64\n",
            "\n",
            "Skewness for Volume Column: 36.042606002811546\n",
            "Kurtosis for Volume Column: 2368.1649879155293\n",
            "\n",
            "Skewness for AdjustmentFactor Column: 122.99565467169053\n",
            "Kurtosis for AdjustmentFactor Column: 17008.27380321588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers from volume column\n",
        "\n",
        "#Step 1: Calculate IQR\n",
        "Q1 = df['Volume'].quantile(0.25)\n",
        "Q3 = df['Volume'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Step 2: Define lower and upper bounds\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Step 3: Filter DataFrame to exclude outliers\n",
        "df_filtered = df[(df['Volume'] >= lower_bound) & (df['Volume'] <= upper_bound)]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4SjopnYdQPrx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics before outlier removal\n",
        "print(\"Summary Statistics for Volume Column (Before):\")\n",
        "print(df['Volume'].describe())\n",
        "\n",
        "# Summary statistics after outlier removal\n",
        "print(\"\\nSummary Statistics for Volume Column (After):\")\n",
        "print(df_filtered['Volume'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al35JOzHQTwY",
        "outputId": "715ecf9b-9873-4a0e-fe3c-d71dad8aba9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics for Volume Column (Before):\n",
            "count    2.332531e+06\n",
            "mean     6.919366e+05\n",
            "std      3.911256e+06\n",
            "min      0.000000e+00\n",
            "25%      3.030000e+04\n",
            "50%      1.071000e+05\n",
            "75%      4.021000e+05\n",
            "max      6.436540e+08\n",
            "Name: Volume, dtype: float64\n",
            "\n",
            "Summary Statistics for Volume Column (After):\n",
            "count    2.024292e+06\n",
            "mean     1.686656e+05\n",
            "std      2.117761e+05\n",
            "min      0.000000e+00\n",
            "25%      2.470000e+04\n",
            "50%      7.830000e+04\n",
            "75%      2.249000e+05\n",
            "max      9.598000e+05\n",
            "Name: Volume, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Log transformation for Volume column\n",
        "df['Volume_Log'] = np.log(df['Volume'])\n",
        "\n",
        "# Display the first few rows to show all columns including the log-transformed Volume\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz3YPKR5QXLW",
        "outputId": "20589c0a-7db6-4427-e9d9-6185d2adaf88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           RowId       Date  SecuritiesCode    Open    High     Low   Close  \\\n",
            "0  20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0  2742.0   \n",
            "1  20170104_1332 2017-01-04            1332   568.0   576.0   563.0   571.0   \n",
            "2  20170104_1333 2017-01-04            1333  3150.0  3210.0  3140.0  3210.0   \n",
            "3  20170104_1376 2017-01-04            1376  1510.0  1550.0  1510.0  1550.0   \n",
            "4  20170104_1377 2017-01-04            1377  3270.0  3350.0  3270.0  3330.0   \n",
            "\n",
            "    Volume  AdjustmentFactor  SupervisionFlag    Target    Class  Volume_Log  \n",
            "0    31400               1.0            False  0.000730  Class 3   10.354563  \n",
            "1  2798500               1.0            False  0.012324  Class 1   14.844594  \n",
            "2   270800               1.0            False  0.006154  Class 4   12.509136  \n",
            "3    11300               1.0            False  0.011053  Class 2    9.332558  \n",
            "4   150800               1.0            False  0.003026  Class 4   11.923710  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max Scaling (Normalization)\n",
        "def min_max_scaling(feature):\n",
        "    min_val = feature.min()\n",
        "    max_val = feature.max()\n",
        "    return (feature - min_val) / (max_val - min_val)\n",
        "\n",
        "# Z-score Normalization (Standardization)\n",
        "def z_score_normalization(feature):\n",
        "    mean = feature.mean()\n",
        "    std_dev = feature.std()\n",
        "    return (feature - mean) / std_dev\n",
        "\n",
        "# Apply Min-Max Scaling and Z-score Normalization to the dataset\n",
        "normalized_df = pd.DataFrame()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype in ['int64', 'float64']:\n",
        "        normalized_df[col + '_minmax'] = min_max_scaling(df[col])\n",
        "        normalized_df[col + '_zscore'] = z_score_normalization(df[col])\n",
        "\n",
        "# Display the normalized dataset\n",
        "print(normalized_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5biUg_gVQaEO",
        "outputId": "c4cf0eaa-e1a2-475a-c8c0-7fe0958e697f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SecuritiesCode_minmax  SecuritiesCode_zscore  Open_minmax  Open_zscore  \\\n",
            "0               0.000000              -1.910785     0.024742     0.039769   \n",
            "1               0.003565              -1.897891     0.005039    -0.566676   \n",
            "2               0.003680              -1.897475     0.028526     0.156243   \n",
            "3               0.008625              -1.879589     0.013608    -0.302931   \n",
            "4               0.008740              -1.879173     0.029617     0.189841   \n",
            "\n",
            "   High_minmax  High_zscore  Low_minmax  Low_zscore  Close_minmax  \\\n",
            "0     0.024800     0.036263    0.025348    0.048551      0.024905   \n",
            "1     0.005078    -0.566714    0.005131   -0.565678      0.005085   \n",
            "2     0.028918     0.162171    0.029173    0.164764      0.029178   \n",
            "3     0.013893    -0.297187    0.013966   -0.297254      0.014023   \n",
            "4     0.030185     0.200913    0.030386    0.201612      0.030273   \n",
            "\n",
            "   Close_zscore  Volume_minmax  Volume_zscore  AdjustmentFactor_minmax  \\\n",
            "0      0.042154       0.000049      -0.168881                 0.045226   \n",
            "1     -0.565803       0.004348       0.538590                 0.045226   \n",
            "2      0.173210       0.000421      -0.107673                 0.045226   \n",
            "3     -0.291648       0.000018      -0.174020                 0.045226   \n",
            "4      0.206815       0.000234      -0.138354                 0.045226   \n",
            "\n",
            "   AdjustmentFactor_zscore  Target_minmax  Target_zscore  Volume_Log_minmax  \\\n",
            "0                -0.007495       0.341139       0.012198                NaN   \n",
            "1                -0.007495       0.347966       0.507697                NaN   \n",
            "2                -0.007495       0.344333       0.243991                NaN   \n",
            "3                -0.007495       0.347218       0.453391                NaN   \n",
            "4                -0.007495       0.342490       0.110296                NaN   \n",
            "\n",
            "   Volume_Log_zscore  \n",
            "0                NaN  \n",
            "1                NaN  \n",
            "2                NaN  \n",
            "3                NaN  \n",
            "4                NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical features\n",
        "encoded_df = pd.get_dummies(df, columns=['SupervisionFlag'])\n",
        "\n",
        "# Display the encoded DataFrame\n",
        "print(encoded_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZXNd70aQeaG",
        "outputId": "1db1d428-ddef-4b07-b618-ec22cb1d3679"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           RowId       Date  SecuritiesCode    Open    High     Low   Close  \\\n",
            "0  20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0  2742.0   \n",
            "1  20170104_1332 2017-01-04            1332   568.0   576.0   563.0   571.0   \n",
            "2  20170104_1333 2017-01-04            1333  3150.0  3210.0  3140.0  3210.0   \n",
            "3  20170104_1376 2017-01-04            1376  1510.0  1550.0  1510.0  1550.0   \n",
            "4  20170104_1377 2017-01-04            1377  3270.0  3350.0  3270.0  3330.0   \n",
            "\n",
            "    Volume  AdjustmentFactor    Target    Class  Volume_Log  \\\n",
            "0    31400               1.0  0.000730  Class 3   10.354563   \n",
            "1  2798500               1.0  0.012324  Class 1   14.844594   \n",
            "2   270800               1.0  0.006154  Class 4   12.509136   \n",
            "3    11300               1.0  0.011053  Class 2    9.332558   \n",
            "4   150800               1.0  0.003026  Class 4   11.923710   \n",
            "\n",
            "   SupervisionFlag_False  SupervisionFlag_True  \n",
            "0                   True                 False  \n",
            "1                   True                 False  \n",
            "2                   True                 False  \n",
            "3                   True                 False  \n",
            "4                   True                 False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the specified columns\n",
        "df = df.drop(columns=['RowId', 'SupervisionFlag'])"
      ],
      "metadata": {
        "id": "wbeKwzTeQh2I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "data_types = df.dtypes\n",
        "\n",
        "# Print data types along with column names\n",
        "print(\"Data Types:\")\n",
        "print(data_types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n8G3AQFUVrE",
        "outputId": "5324b2de-3d65-492b-ce2a-64c751ea8022"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types:\n",
            "Date                datetime64[ns]\n",
            "SecuritiesCode               int64\n",
            "Open                       float64\n",
            "High                       float64\n",
            "Low                        float64\n",
            "Close                      float64\n",
            "Volume                       int64\n",
            "AdjustmentFactor           float64\n",
            "Target                     float64\n",
            "Class                       object\n",
            "Volume_Log                 float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Class' column and store the encoded values in a new column 'Class_encoded'\n",
        "stock_prices_df['Class_encoded'] = label_encoder.fit_transform(stock_prices_df['Class'])\n",
        "\n",
        "# Display the DataFrame with encoded classes\n",
        "print(stock_prices_df[['RowId', 'Close', 'Class', 'Class_encoded']])\n",
        "\n",
        "# Drop the original 'Class' column\n",
        "stock_prices_df = stock_prices_df.drop(columns=['Class'])\n",
        "\n",
        "# Verify column names after dropping 'Class'\n",
        "print(stock_prices_df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoj97C1QYxDR",
        "outputId": "a312b8f7-2656-4be9-dc83-2755c6a354e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 RowId   Close    Class  Class_encoded\n",
            "0        20170104_1301  2742.0  Class 3              2\n",
            "1        20170104_1332   571.0  Class 1              0\n",
            "2        20170104_1333  3210.0  Class 4              3\n",
            "3        20170104_1376  1550.0  Class 2              1\n",
            "4        20170104_1377  3330.0  Class 4              3\n",
            "...                ...     ...      ...            ...\n",
            "2332526  20211203_9990   528.0  Class 1              0\n",
            "2332527  20211203_9991   794.0  Class 1              0\n",
            "2332528  20211203_9993  1645.0  Class 2              1\n",
            "2332529  20211203_9994  2389.0  Class 3              2\n",
            "2332530  20211203_9997   696.0  Class 1              0\n",
            "\n",
            "[2332531 rows x 4 columns]\n",
            "Index(['RowId', 'Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close',\n",
            "       'Volume', 'AdjustmentFactor', 'SupervisionFlag', 'Target', 'Volume_Log',\n",
            "       'Class_encoded'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Class' column\n",
        "df['Class_encoded'] = label_encoder.fit_transform(df['Class'])\n"
      ],
      "metadata": {
        "id": "YioJtERhSMde"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Class' column\n",
        "df = df.drop(columns=['Class'])\n"
      ],
      "metadata": {
        "id": "dzor6kApSP9V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Calculate the total number of samples\n",
        "N_total = df.shape[0]\n",
        "\n",
        "# Specify the proportions for training, validation, and testing sets\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1  # Splitting the remaining data equally for validation and testing\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Calculate the number of samples for each set\n",
        "N_train = math.floor(train_ratio * N_total)\n",
        "N_val = math.floor(val_ratio * N_total)\n",
        "N_test = N_total - N_train - N_val\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "X_train = df.iloc[:N_train, :-1]  # Assuming the last column is the target column\n",
        "y_train = df.iloc[:N_train, -1]   # Assuming the last column is the target column\n",
        "\n",
        "X_val = df.iloc[N_train:N_train + N_val, :-1]\n",
        "y_val = df.iloc[N_train:N_train + N_val, -1]\n",
        "\n",
        "X_test = df.iloc[N_train + N_val:, :-1]\n",
        "y_test = df.iloc[N_train + N_val:, -1]\n",
        "\n",
        "# Print the number of samples in the validation set\n",
        "print(\"Number of samples in the validation set:\", N_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXpA80Y6QnhA",
        "outputId": "884cdd1f-bcd2-45a0-c37d-60d7d4367766"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the validation set: 233253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXKg5ycqROll",
        "outputId": "e0f50c8e-383f-488e-c7b5-8cbfe34de1f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1866024"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "MbN1sYT2RSki"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgpzBrxERVNl",
        "outputId": "8d7fabf1-f19b-4a25-a6c5-fa38e517d3f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st Hidden layer\n",
        "X_train.shape[1]*12 + 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_OJ5BosRXx5",
        "outputId": "4cb665d1-e73e-45c5-f3a0-c1f2d2a85753"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd Hidden layer\n",
        "12 * 8 + 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7DYiXW_RX64",
        "outputId": "22628ece-df78-4de0-c679-51788c9c0cbd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3rd Hidden layer\n",
        "8 * 8 + 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjCOdcH_Rc8U",
        "outputId": "16ef63a2-5198-4762-9f8c-1687b1734f60"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByabfQEcRfaF",
        "outputId": "2dd68a3a-c0dd-435c-e18a-2143477e43fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                132       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 317 (1.24 KB)\n",
            "Trainable params: 317 (1.24 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "in_x = Input(shape = X_train.shape[1:])\n",
        "x = Dense(12, input_dim=X_train.shape[1], activation='relu')(in_x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "out_x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(in_x,out_x)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDVdzoCERhfx",
        "outputId": "21113f22-22e2-462a-fd00-7a76c3f470b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 12)                132       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 317 (1.24 KB)\n",
            "Trainable params: 317 (1.24 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.activations import relu\n",
        "import keras\n",
        "\n",
        "in_x = Input(shape = X_train.shape[1:])\n",
        "x = keras.layers.Normalization(axis=-1)(in_x)\n",
        "x = Dense(12, input_dim=X_train.shape[1], activation='relu')(in_x)\n",
        "x = Dense(8)(x)\n",
        "x = relu(x)\n",
        "out_x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(in_x,out_x)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFFlfa_TRk69",
        "outputId": "f2ffa91a-11dd-4910-bbca-4792cea5648b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                132       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " tf.nn.relu (TFOpLambda)     (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245 (980.00 Byte)\n",
            "Trainable params: 245 (980.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "li3vCfUmRokK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop timestamp columns from X_train and X_Test\n",
        "X_train_numeric = X_train.drop(columns=['timestamp_column1', 'timestamp_column2', ...], errors='ignore')\n",
        "X_test_numeric = X_test.drop(columns=['timestamp_column1', 'timestamp_column2', ...], errors='ignore')\n",
        "\n",
        "# Convert all columns to numeric (excluding the timestamp columns)\n",
        "X_train_numeric = X_train_numeric.apply(pd.to_numeric, errors='ignore')\n",
        "X_test_numeric = X_test_numeric.apply(pd.to_numeric, errors='ignore')\n",
        "\n",
        "# Convert to NumPy array and cast to float\n",
        "X_train_numeric_array = X_train_numeric.to_numpy().astype(\"float\")\n",
        "X_test_numeric_array = X_test_numeric.to_numpy().astype(\"float\")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_numeric_array,\n",
        "                    y_train.to_numpy().astype(\"float\"),\n",
        "                    validation_data=(X_test_numeric_array, y_test.to_numpy().astype(\"float\")),\n",
        "                    epochs=100,\n",
        "                    batch_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Wk9mDsRx7T",
        "outputId": "10f00668-4f05-4fc6-a202-43b958194de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "186603/186603 [==============================] - 389s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 2/100\n",
            "186603/186603 [==============================] - 381s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 3/100\n",
            "186603/186603 [==============================] - 383s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 4/100\n",
            "186603/186603 [==============================] - 373s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 5/100\n",
            "186603/186603 [==============================] - 373s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 6/100\n",
            "186603/186603 [==============================] - 397s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 7/100\n",
            "186603/186603 [==============================] - 384s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 8/100\n",
            "186603/186603 [==============================] - 392s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 9/100\n",
            "186603/186603 [==============================] - 395s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 10/100\n",
            "186603/186603 [==============================] - 415s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 11/100\n",
            "186603/186603 [==============================] - 401s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 12/100\n",
            "186603/186603 [==============================] - 404s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 13/100\n",
            "186603/186603 [==============================] - 419s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 14/100\n",
            "186603/186603 [==============================] - 403s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 15/100\n",
            "186603/186603 [==============================] - 398s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 16/100\n",
            "186603/186603 [==============================] - 409s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 17/100\n",
            "186603/186603 [==============================] - 404s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 18/100\n",
            "186603/186603 [==============================] - 404s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 19/100\n",
            "186603/186603 [==============================] - 406s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 20/100\n",
            "186603/186603 [==============================] - 409s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 21/100\n",
            "186603/186603 [==============================] - 407s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 22/100\n",
            "186603/186603 [==============================] - 394s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 23/100\n",
            "186603/186603 [==============================] - 391s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 24/100\n",
            "186603/186603 [==============================] - 415s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 25/100\n",
            "186603/186603 [==============================] - 401s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 26/100\n",
            "186603/186603 [==============================] - 397s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 27/100\n",
            "186603/186603 [==============================] - 416s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 28/100\n",
            "186603/186603 [==============================] - 416s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 29/100\n",
            "186603/186603 [==============================] - 410s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 30/100\n",
            "186603/186603 [==============================] - 396s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 31/100\n",
            "186603/186603 [==============================] - 394s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 32/100\n",
            "186603/186603 [==============================] - 386s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 33/100\n",
            "186603/186603 [==============================] - 393s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 34/100\n",
            "186603/186603 [==============================] - 380s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 35/100\n",
            "186603/186603 [==============================] - 393s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 36/100\n",
            "186603/186603 [==============================] - 383s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 37/100\n",
            "186603/186603 [==============================] - 395s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 38/100\n",
            "186603/186603 [==============================] - 383s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 39/100\n",
            "186603/186603 [==============================] - 383s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 40/100\n",
            "186603/186603 [==============================] - 380s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 41/100\n",
            "186603/186603 [==============================] - 389s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 42/100\n",
            "186603/186603 [==============================] - 373s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 43/100\n",
            "186603/186603 [==============================] - 392s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 44/100\n",
            "186603/186603 [==============================] - 382s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 45/100\n",
            "186603/186603 [==============================] - 393s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 46/100\n",
            "186603/186603 [==============================] - 394s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 47/100\n",
            "186603/186603 [==============================] - 381s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 48/100\n",
            "186603/186603 [==============================] - 387s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 49/100\n",
            "186603/186603 [==============================] - 383s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 50/100\n",
            "186603/186603 [==============================] - 409s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 51/100\n",
            "186603/186603 [==============================] - 391s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 52/100\n",
            "186603/186603 [==============================] - 406s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 53/100\n",
            "186603/186603 [==============================] - 406s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 54/100\n",
            "186603/186603 [==============================] - 395s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 55/100\n",
            "186603/186603 [==============================] - 394s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 56/100\n",
            "186603/186603 [==============================] - 400s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 57/100\n",
            "186603/186603 [==============================] - 399s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 58/100\n",
            "  2173/186603 [..............................] - ETA: 5:23 - loss: nan - accuracy: 0.2581"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop timestamp columns from X_train and X_Test\n",
        "X_train_numeric = X_train.drop(columns=['timestamp_column1', 'timestamp_column2', ...], errors='ignore')\n",
        "X_test_numeric = X_test.drop(columns=['timestamp_column1', 'timestamp_column2', ...], errors='ignore')\n",
        "\n",
        "# Convert all columns to numeric (excluding the timestamp columns)\n",
        "X_train_numeric = X_train_numeric.apply(pd.to_numeric, errors='ignore')\n",
        "X_test_numeric = X_test_numeric.apply(pd.to_numeric, errors='ignore')\n",
        "\n",
        "# Convert to NumPy array and cast to float\n",
        "X_train_numeric_array = X_train_numeric.to_numpy().astype(\"float\")\n",
        "X_test_numeric_array = X_test_numeric.to_numpy().astype(\"float\")\n",
        "\n",
        "# Continue training the model from epoch 58 to epoch 100\n",
        "history = model.fit(X_train_numeric_array,\n",
        "                    y_train.to_numpy().astype(\"float\"),\n",
        "                    validation_data=(X_test_numeric_array, y_test.to_numpy().astype(\"float\")),\n",
        "                    epochs=100,\n",
        "                    initial_epoch=57,  # Start from epoch 58\n",
        "                    batch_size=10)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c9ym34CJ64B",
        "outputId": "28b05a9a-4655-4712-d128-e9c7c7311ebe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100\n",
            "186603/186603 [==============================] - 519s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 59/100\n",
            "186603/186603 [==============================] - 508s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 60/100\n",
            "186603/186603 [==============================] - 478s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 61/100\n",
            "186603/186603 [==============================] - 474s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 62/100\n",
            "186603/186603 [==============================] - 482s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 63/100\n",
            "186603/186603 [==============================] - 474s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 64/100\n",
            "186603/186603 [==============================] - 496s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 65/100\n",
            "186603/186603 [==============================] - 496s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 66/100\n",
            "186603/186603 [==============================] - 512s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 67/100\n",
            "186603/186603 [==============================] - 476s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 68/100\n",
            "186603/186603 [==============================] - 466s 2ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 69/100\n",
            "186603/186603 [==============================] - 499s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 70/100\n",
            "186603/186603 [==============================] - 496s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 71/100\n",
            "186603/186603 [==============================] - 488s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 72/100\n",
            "186603/186603 [==============================] - 471s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 73/100\n",
            "186603/186603 [==============================] - 473s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 74/100\n",
            "186603/186603 [==============================] - 482s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 75/100\n",
            "186603/186603 [==============================] - 472s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 76/100\n",
            "186603/186603 [==============================] - 479s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 77/100\n",
            "186603/186603 [==============================] - 476s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 78/100\n",
            "186603/186603 [==============================] - 477s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 79/100\n",
            "186603/186603 [==============================] - 482s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 80/100\n",
            "186603/186603 [==============================] - 477s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 81/100\n",
            "186603/186603 [==============================] - 544s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 82/100\n",
            "186603/186603 [==============================] - 499s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 83/100\n",
            "186603/186603 [==============================] - 484s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 84/100\n",
            "186603/186603 [==============================] - 473s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 85/100\n",
            "186603/186603 [==============================] - 467s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 86/100\n",
            "186603/186603 [==============================] - 495s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 87/100\n",
            "186603/186603 [==============================] - 491s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 88/100\n",
            "186603/186603 [==============================] - 507s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 89/100\n",
            "186603/186603 [==============================] - 488s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 90/100\n",
            "186603/186603 [==============================] - 494s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 91/100\n",
            "186603/186603 [==============================] - 494s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 92/100\n",
            "186603/186603 [==============================] - 500s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 93/100\n",
            "186603/186603 [==============================] - 487s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 94/100\n",
            "186603/186603 [==============================] - 485s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 95/100\n",
            "186603/186603 [==============================] - 530s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 96/100\n",
            "186603/186603 [==============================] - 500s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 97/100\n",
            "186603/186603 [==============================] - 486s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 98/100\n",
            "186603/186603 [==============================] - 500s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 99/100\n",
            "186603/186603 [==============================] - 491s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n",
            "Epoch 100/100\n",
            "186603/186603 [==============================] - 489s 3ms/step - loss: nan - accuracy: 0.2538 - val_loss: nan - val_accuracy: 0.2279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print (history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om95hoa_NEhj",
        "outputId": "ff2cbef5-7674-4338-960f-596314d1da97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711, 0.2538290023803711], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886, 0.22787605226039886]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jcimCdDwgYD8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(history.history[\"loss\"])),history.history[\"loss\"],label=\"Training Loss\")\n",
        "plt.plot(range(len(history.history[\"val_loss\"])),history.history[\"val_loss\"],label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "yMAAkOPK9Nkf",
        "outputId": "95d6f6fe-fd50-4d78-d590-e676eca5456f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b83c235e530>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(history.history[\"accuracy\"])),history.history[\"accuracy\"],label=\"Training accuracy\")\n",
        "plt.plot(range(len(history.history[\"val_accuracy\"])),history.history[\"val_accuracy\"],label=\"Validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "TlqMKOUJ9Q2J",
        "outputId": "6210f072-41db-4426-dd00-d681566261cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b83c2275450>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Bl2bY5399VHN",
        "outputId": "36231372-99af-4160-bb57-40cd596abf20"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-08d5afcd86bf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert \"date\" column to Unix timestamp\n",
        "X_test['Date'] = pd.to_datetime(X_test['Date']).astype(int) / 10**9\n",
        "\n",
        "# Proceed with model evaluation\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKugpgLYhNWT",
        "outputId": "57146fa2-28ec-4455-d2b8-077ddd17c106"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7290/7290 [==============================] - 14s 2ms/step - loss: nan - accuracy: 0.2279\n",
            "[nan, 0.22787605226039886]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1WPVGo9Vnx",
        "outputId": "282ca0e1-a515-46ca-92d0-0ffb27dfe500"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7290/7290 [==============================] - 15s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       ...,\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_0 = X_test[(y_test==0).to_numpy()]\n",
        "X_test_1 = X_test[(y_test==1).to_numpy()]"
      ],
      "metadata": {
        "id": "GonuDilT9Xx_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist,bins,_= plt.hist(model.predict(X_test_0),density=1,bins=50,alpha=0.5,label=\"Target 0\")\n",
        "hist,bins,_= plt.hist(model.predict(X_test_1),density=1,bins=bins,alpha=0.5,label=\"Target 1\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "TU7v3tkr9cQh",
        "outputId": "7b183053-56f2-4313-85cb-a6a5585ce78d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1662/1662 [==============================] - 8s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py:6762: RuntimeWarning: All-NaN slice encountered\n",
            "  xmin = min(xmin, np.nanmin(xi))\n",
            "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py:6763: RuntimeWarning: All-NaN slice encountered\n",
            "  xmax = max(xmax, np.nanmax(xi))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "autodetected range of [nan, nan] is not finite",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-ff9be0b14491>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Target 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Target 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vertical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2644\u001b[0m         label=None, stacked=False, *, data=None, **kwargs):\n\u001b[0;32m-> 2645\u001b[0;31m     return gca().hist(\n\u001b[0m\u001b[1;32m   2646\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0mcumulative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcumulative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6788\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6789\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6790\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6791\u001b[0m             \u001b[0mtops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6792\u001b[0m         \u001b[0mtops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, density, weights)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m     \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`bins` must be positive, when an integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[0;34m(a, range)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: autodetected range of [nan, nan] is not finite"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check for NaN values in predictions for target 0\n",
        "predictions_0 = model.predict(X_test_0)\n",
        "if np.isnan(predictions_0).any():\n",
        "    print(\"Warning: NaN values found in predictions for target 0.\")\n",
        "else:\n",
        "    hist, bins, _ = plt.hist(predictions_0, density=1, bins=50, alpha=0.5, label=\"Target 0\")\n",
        "\n",
        "# Check for NaN values in predictions for target 1\n",
        "predictions_1 = model.predict(X_test_1)\n",
        "if np.isnan(predictions_1).any():\n",
        "    print(\"Warning: NaN values found in predictions for target 1.\")\n",
        "else:\n",
        "    hist, bins, _ = plt.hist(predictions_1, density=1, bins=bins, alpha=0.5, label=\"Target 1\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "zNzNFw-Ui5jk",
        "outputId": "28da92af-6570-4e4a-b726-c05283ba4e3c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1662/1662 [==============================] - 4s 2ms/step\n",
            "Warning: NaN values found in predictions for target 0.\n",
            "1744/1744 [==============================] - 3s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN values found in predictions for target 1.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, _ = roc_curve(y_test, model.predict(X_test))\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Kpao9IUK9fMv",
        "outputId": "6f71b6e9-4df0-4489-ecbc-c439b8d23601"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7290/7290 [==============================] - 17s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multiclass format is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e34ad01c5808>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/drive/MyDrive/Saved Models.hdfs')"
      ],
      "metadata": {
        "id": "j__rKEhX9iiz"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison with my previous model"
      ],
      "metadata": {
        "id": "IwJIWPUYJpNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the Node class for the Decision Tree\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature  # Feature index for splitting\n",
        "        self.threshold = threshold  # Threshold for splitting\n",
        "        self.left = left  # Left child node\n",
        "        self.right = right  # Right child node\n",
        "        self.value = value  # Value for leaf nodes\n",
        "\n",
        "# Define the Decision Tree class\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y.astype(int))\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_row(x, self.root) for x in X])\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_classes = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or n_classes == 1 or n_samples < self.min_samples_split:\n",
        "            value = np.bincount(y).argmax()\n",
        "            return Node(value=value)\n",
        "\n",
        "        # Find the best split\n",
        "        best_gini = float('inf')\n",
        "        best_feature, best_threshold = None, None\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        # Split the dataset\n",
        "        left_indices = np.where(X[:, best_feature] <= best_threshold)[0]\n",
        "        right_indices = np.where(X[:, best_feature] > best_threshold)[0]\n",
        "        left_child = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_child = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
        "\n",
        "    def _predict_row(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_row(x, node.left)\n",
        "        else:\n",
        "            return self._predict_row(x, node.right)\n",
        "\n",
        "    def _gini_impurity(self, left_y, right_y):\n",
        "        n = len(left_y) + len(right_y)\n",
        "        p_left = len(left_y) / n\n",
        "        p_right = len(right_y) / n\n",
        "        return p_left * self._calc_gini(left_y) + p_right * self._calc_gini(right_y)\n",
        "\n",
        "    def _calc_gini(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        p = np.bincount(np.round(y).astype(int)) / len(y)\n",
        "        return 1 - np.sum(p ** 2)\n",
        "\n",
        "\n",
        "# Define the size of the test set (e.g., 20% of the total data)\n",
        "test_size = 0.2\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_data = df.sample(frac=1-test_size, random_state=42)  # Use 80% of the data for training\n",
        "test_data = df.drop(train_data.index)  # Use the remaining 20% for testing\n",
        "\n",
        "# Example usage:\n",
        "# Instantiate and train the model\n",
        "tree = DecisionTree(max_depth=3)\n",
        "X_train = train_data.drop(columns=['Close']).values\n",
        "y_train = train_data['Close'].values\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "X_test = test_data.drop(columns=['Close']).values\n",
        "predictions = tree.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Pg46SGnhI9Df",
        "outputId": "7bbf716d-5d35-4d4a-9ed9-f749bb522104"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-5d4c28197734>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-5d4c28197734>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-5d4c28197734>\u001b[0m in \u001b[0;36m_grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mleft_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mright_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the Node class for the Decision Tree\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature  # Feature index for splitting\n",
        "        self.threshold = threshold  # Threshold for splitting\n",
        "        self.left = left  # Left child node\n",
        "        self.right = right  # Right child node\n",
        "        self.value = value  # Value for leaf nodes\n",
        "\n",
        "# Define the Decision Tree class\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y.astype(int))\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_row(x, self.root) for x in X])\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_classes = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or n_classes == 1 or n_samples < self.min_samples_split:\n",
        "            value = np.bincount(y).argmax()\n",
        "            return Node(value=value)\n",
        "\n",
        "        # Find the best split\n",
        "        best_gini = float('inf')\n",
        "        best_feature, best_threshold = None, None\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        # Split the dataset\n",
        "        left_indices = np.where(X[:, best_feature] <= best_threshold)[0]\n",
        "        right_indices = np.where(X[:, best_feature] > best_threshold)[0]\n",
        "        left_child = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_child = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
        "\n",
        "    def _predict_row(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_row(x, node.left)\n",
        "        else:\n",
        "            return self._predict_row(x, node.right)\n",
        "\n",
        "    def _gini_impurity(self, left_y, right_y):\n",
        "        n = len(left_y) + len(right_y)\n",
        "        p_left = len(left_y) / n\n",
        "        p_right = len(right_y) / n\n",
        "        return p_left * self._calc_gini(left_y) + p_right * self._calc_gini(right_y)\n",
        "\n",
        "    def _calc_gini(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        p = np.bincount(np.round(y).astype(int)) / len(y)\n",
        "        return 1 - np.sum(p ** 2)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' contains your DataFrame with the 'Close' column\n",
        "# Instantiate and train the model\n",
        "tree = DecisionTree(max_depth=3)\n",
        "X_train = train_data.drop(columns=['Close']).values\n",
        "y_train = train_data['Close'].values\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "X_test = test_data.drop(columns=['Close']).values\n",
        "predictions = tree.predict(X_test)\n",
        "\n",
        "# Create a DataFrame to store predictions\n",
        "predictions_df = pd.DataFrame()\n",
        "\n",
        "# Assign 'Date' column from 'test_data' to the predictions DataFrame\n",
        "predictions_df['Date'] = test_data['Date']\n",
        "\n",
        "# Reset index to start from 0\n",
        "predictions_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Assign the predicted values to the 'Close' column\n",
        "predictions_df['Close'] = predictions\n",
        "\n",
        "# Add a placeholder for the 'Rank' column (you'll compute it later)\n",
        "predictions_df['Rank'] = np.arange(len(predictions_df))\n",
        "\n",
        "# Now predictions_df should have the required structure\n",
        "print(predictions_df.head())"
      ],
      "metadata": {
        "id": "xyzkQ6aF9oXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = np.mean(np.abs(test_data['Close'] - predictions))\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = np.mean((test_data['Close'] - predictions) ** 2)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(test_data['Date'], test_data['Close'], label='Actual Close')\n",
        "plt.plot(test_data['Date'], predictions, label='Predicted Close')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.title('Actual vs Predicted Close Prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SgNoIDP5Jn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ML to the Challenge Data Set"
      ],
      "metadata": {
        "id": "UHc08LV5-tQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions on the test data\n",
        "X_test = test_data.drop(columns=['Close']).values\n",
        "predictions_test = tree.predict(X_test)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions_test)"
      ],
      "metadata": {
        "id": "AUhPLYO_-jn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "X_test = test_data.drop(columns=['Close']).values\n",
        "y_test = test_data['Close'].values\n",
        "predictions_test = tree.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\"Compute the accuracy score.\"\"\"\n",
        "    correct = sum(y_true == y_pred)\n",
        "    total = len(y_true)\n",
        "    return correct / total\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions_test)\n",
        "print(\"Accuracy on test set:\", accuracy)"
      ],
      "metadata": {
        "id": "Jswuv_y7-muD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n"
      ],
      "metadata": {
        "id": "U2pbilhV-xO7"
      }
    }
  ]
}