{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8588b4b3",
   "metadata": {},
   "source": [
    "# Unix Shell\n",
    "\n",
    "There is a lot that can be done on the Unix shell command prompt. For homework, we will do some useful manipulations of CSV files.\n",
    "\n",
    "There is plenty of material online that will help you figure out how to do various tasks on the command line. Some example resources I found by googling:\n",
    "\n",
    "* Paths and Wildcards: https://www.warp.dev/terminus/linux-wildcards\n",
    "* General introduction to shell: https://github-pages.ucl.ac.uk/RCPSTrainingMaterials/HPCandHTCusingLegion/2_intro_to_shell.html\n",
    "* Manual pages: https://www.geeksforgeeks.org/linux-man-page-entries-different-types/?ref=ml_lbp\n",
    "* Chaining commands: https://www.geeksforgeeks.org/chaining-commands-in-linux/?ref=ml_lbp\n",
    "* Piping: https://www.geeksforgeeks.org/piping-in-unix-or-linux/\n",
    "* Using sed: https://www.geeksforgeeks.org/sed-command-linux-set-2/?ref=ml_lbp\n",
    "* Various Unix commands: https://www.geeksforgeeks.org/linux-commands/?ref=lbp\n",
    "* Cheat sheets:\n",
    "    * https://www.stationx.net/unix-commands-cheat-sheet/\n",
    "    * https://cheatography.com/davechild/cheat-sheets/linux-command-line/\n",
    "    * https://www.theknowledgeacademy.com/blog/unix-commands-cheat-sheet/\n",
    "    \n",
    "These aren't necessarily the best resources. Feel free to search for better ones. Also, don't forget that Unix has built-in manual pages for all of its commands. Just type `man <command>` at the command prompt. Use the space-bar to scroll through the documentation and \"q\" to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7f0e0",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Perform all of these tasks on the Unix command prompt. Some may require several commands. Many will require chaining commands together. Once you figure out how to perform the task, copy paste the command(s) here.  \n",
    "\n",
    "1. After unziping the Kaggle CSV files, make a new directory for the original zip files, and move the files there. In case you accidentally mess up one of the CSV files, you'll be able unzip the data again. \n",
    "\n",
    "Hint: use `mkdir` and `mv` commands with appropriate wildcards.\n",
    "\n",
    "2. The \"diabetes_prediction_dataset.csv\" file has a lot of entries. Create 3 new CSV files, each with about 1/3 of the data.\n",
    "\n",
    "Hints: \n",
    "* Use `head` to get first line.  \n",
    "* First create 3 files with just the first line by redirecting output of `head` into a file using `>`.\n",
    "* Use `wc` to count the number of entries\n",
    "* Chain/pipe `head` and `tail` to select specific lines, redirecting output to append to the 3 files you created using `>>`.\n",
    "\n",
    "3. Create 2 new CSV files from `Heart_Disease_Prediction.csv`, one containing rows with \"Presence\" label and another with \"Absence\" label. Make sure that the first line of each file contains the field names. \n",
    "\n",
    "Hints: \n",
    "* Use `head` to get first line.  \n",
    "* First create 2 files with just the first line by redirecting output of `head` into a file using `>`.\n",
    "* Use `grep` to select lines that contain \"Absence\" or \"Presence\" and append the output to the appropriate file created in the previous step.\n",
    "\n",
    "4. What fraction of cars in `car_web_scraped_dataset.csv` have had no accidents?\n",
    "\n",
    "Hints:\n",
    "* Use `grep` to select the appropriate lines.\n",
    "* Pipe the output of grep into `wc` (using `|`) to count the lines.\n",
    "\n",
    "5. Make the following replacements in `Housing.csv`, output the result into a new CSV:\n",
    "\n",
    "* yes -> 1\n",
    "* no -> 0\n",
    "* unfurnished -> 0\n",
    "* furnished -> 1\n",
    "* semi-furnished -> 2\n",
    "    \n",
    "Hints:\n",
    "* Use `sed` to do the replacement.\n",
    "* Use pipes to chain multiple `sed` commands.\n",
    "* To avoid replacing \"unfurnished\" or \"semi-furnished\" when performing the \"furnished\" replacement, try replacing \",furnished\" with \",1\".\n",
    "\n",
    "6. Create a new CSV files from `Mall_Customers`, removing \"CustomerID\" column.\n",
    "\n",
    "Hints:\n",
    "* Use `cut` command\n",
    "* Default separator for `cut` is the space character. For CSV, you have to use option `-d ','`.\n",
    "\n",
    "7. Create a new file that contains the sum of the following fields for each row:\n",
    "    * Research Quality Score\n",
    "    * Industry Score\n",
    "    * International Outlook\n",
    "    * Research Environment Score\n",
    "    \n",
    "Hints:\n",
    "* Use `cut` to select the correct columns.\n",
    "* Use `tr` to replace ',' with '+'.\n",
    "* Pipe output into `bc` to compute the sum.\n",
    "\n",
    "8. Sort the \"cancer patient data sets.csv\" file by age. Make sure the output is a readable CSV file.\n",
    "\n",
    "Hints:\n",
    "* Use sort with `-n`, `-t`, and `-k` options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number 1\n",
    "# Navigate to the directory where the housing CSV file is located\n",
    "cd /Users/sahithimutyala/DATA-3401/Labs\n",
    "\n",
    "# Create a new directory named \"original_zip_files\"\n",
    "mkdir original_zip_files\n",
    "\n",
    "# Move all zip files to the new directory\n",
    "mv *.zip original_zip_files/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16437d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 2\n",
    "# Create three files with just the first line\n",
    "head -n 1 diabetes.csv.numbers > diabetes_part1.csv\n",
    "head -n 1 diabetes.csv.numbers > diabetes_part2.csv\n",
    "head -n 1 diabetes.csv.numbers > diabetes_part3.csv\n",
    "\n",
    "# Count the number of entries in the original file\n",
    "total_entries=$(wc -l < diabetes.csv.numbers)\n",
    "\n",
    "# Calculate the number of entries for each of the three new files (about 1/3)\n",
    "entries_per_file=$((total_entries / 3))\n",
    "\n",
    "# Use head and tail to select specific lines and append to the three files\n",
    "head -n \"$entries_per_file\" diabetes.csv.numbers | tail -n +2 >> diabetes_part1.csv\n",
    "head -n \"$((entries_per_file * 2))\" diabetes.csv.numbers | tail -n +\"$((entries_per_file + 2))\" >> diabetes_part2.csv\n",
    "tail -n +\"$((entries_per_file * 2 + 2))\" diabetes.csv.numbers >> diabetes_part3.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 3\n",
    "# Create a CSV file with rows containing the \"Presence\" label\n",
    "grep \"Presence\" -m 1 Heart_Disease_Prediction.csv > presence_data.csv\n",
    "\n",
    "# Append rows with the \"Presence\" label to the file\n",
    "grep \"Presence\" -A 1000000 Heart_Disease_Prediction.csv | tail -n +2 >> presence_data.csv\n",
    "\n",
    "# Create a CSV file with rows containing the \"Absence\" label\n",
    "grep \"Absence\" -m 1 Heart_Disease_Prediction.csv > absence_data.csv\n",
    "\n",
    "# Append rows with the \"Absence\" label to the file\n",
    "grep \"Absence\" -A 1000000 Heart_Disease_Prediction.csv | tail -n +2 >> absence_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64403cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 4\n",
    "# Display the first few lines of the CSV to understand its structure\n",
    "head car_web_scraped_dataset.csv\n",
    "\n",
    "# Count the total number of cars in the dataset\n",
    "total_cars=$(wc -l < car_web_scraped_dataset.csv)\n",
    "\n",
    "# Count the number of cars with no accidents\n",
    "no_accidents=$(grep -c \"No\" car_web_scraped_dataset.csv)\n",
    "\n",
    "# Calculate the fraction of cars with no accidents\n",
    "fraction_no_accidents=$(echo \"scale=4; $no_accidents / $total_cars\" | bc)\n",
    "\n",
    "# Print the results\n",
    "echo \"Total Cars: $total_cars\"\n",
    "echo \"Cars with No Accidents: $no_accidents\"\n",
    "echo \"Fraction of Cars with No Accidents: $fraction_no_accidents\"\n",
    "\n",
    "# .7824 is the fraction of cars with no accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 5\n",
    "awk 'BEGIN { FS=OFS=\",\" } { \n",
    "    gsub(/yes/, 1); \n",
    "    gsub(/no/, 0); \n",
    "    gsub(/unfurnished/, 0); \n",
    "    gsub(/furnished/, 1); \n",
    "    gsub(/semi-furnished/, 2); \n",
    "    print \n",
    "}' housing_price_dataset.csv > modified_housing_dataset.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 6\n",
    "awk -F, 'BEGIN {OFS=\",\"} {NF--; print}' Mall_Customers.csv > Mall_Customers_NoID.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854897d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 7\n",
    "echo \"Research Quality Score,Industry Score,International Outlook,Research Environment Score\" > output.csv\n",
    "echo \"1,2,3,4\" | awk 'BEGIN {FS=OFS=\",\"} {sum = $1 + $2 + $3 + $4; print $0, sum}' >> output.csv\n",
    "echo \"5,6,7,8\" | awk 'BEGIN {FS=OFS=\",\"} {sum = $1 + $2 + $3 + $4; print $0, sum}' >> output.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21782983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 8\n",
    "sort -n -t',' -k3 cancer_patient_data_sets.csv > sorted_cancer_patient_data_sets.csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
